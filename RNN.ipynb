{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "import string\n",
    "from pickle import dump\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model\n",
    "from pickle import load\n",
    "import re\n",
    "\n",
    "def load_doc(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess each word\n",
    "def parse_word(word):\n",
    "    word = word.lower()\n",
    "    #delete puncuations\n",
    "    if word.endswith(','): \n",
    "        word = word[:-1]\n",
    "    if word.endswith('.'):\n",
    "        word = word[:-1]\n",
    "    if word.endswith('?'): \n",
    "        word = word[:-1]\n",
    "    if word.endswith('!'): \n",
    "        word = word[:-1]\n",
    "    if word.endswith('?'): \n",
    "        word = word[:-1]\n",
    "    if word.endswith(';'): \n",
    "        word = word[:-1]\n",
    "    if word.endswith(':'): \n",
    "        word = word[:-1]\n",
    "    if word.endswith(')'): \n",
    "        word = word[:-1]\n",
    "    if word.endswith(\"'\"):\n",
    "        if word != \"th'\":\n",
    "            word = word[:-1]\n",
    "    if word.startswith('('):\n",
    "        word = word[1:]\n",
    "    if word.startswith(\"'\"):\n",
    "        word = word[1:]\n",
    "    return word\n",
    "\n",
    "def get_text(filename):    \n",
    "    with open(filename) as f:\n",
    "        text = ''\n",
    "        for line in f:\n",
    "            if line.split() == []:\n",
    "                continue\n",
    "            if line.split()[0].isdigit():\n",
    "                continue   \n",
    "            #add the words in the poem\n",
    "            for word in line.split():\n",
    "                #preprocess\n",
    "                #word = parse_word(word) #somehow we want to predict puncutation here\n",
    "                text += word + ' '\n",
    "    f.close()\n",
    "    return text\n",
    "\n",
    "fp = r'C:\\\\Users\\\\happy\\\\Desktop\\\\project 3\\\\Official_Release\\\\data\\\\shakespeare.txt'\n",
    "raw_text = get_text(fp)\n",
    "#print(raw_text)\n",
    "\n",
    "#not sure if i should train using all poems or one poem by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14474103071045859987\n",
      "]\n",
      "WARNING:tensorflow:From C:\\Users\\happy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\happy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\happy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\happy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus() #sadly no gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sequences: 93634\n"
     ]
    }
   ],
   "source": [
    "#organize into sequence of characters\n",
    "length = 40\n",
    "sequence = list()\n",
    "for i in range(length, len(raw_text)):\n",
    "    seq = raw_text[i-length:i+1]\n",
    "    sequence.append(seq)\n",
    "print(\"total sequences: %d\" % len(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save stuff to file for some reason, otherwise might have memory issue\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close\n",
    "\n",
    "#save shit to file\n",
    "out_f = 'dark_char.txt'\n",
    "save_doc(sequence, out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From fairest creatures we desire increase\n",
      "['\\n', ' ', '!', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, ':': 9, ';': 10, '?': 11, 'A': 12, 'B': 13, 'C': 14, 'D': 15, 'E': 16, 'F': 17, 'G': 18, 'H': 19, 'I': 20, 'J': 21, 'K': 22, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'R': 28, 'S': 29, 'T': 30, 'U': 31, 'V': 32, 'W': 33, 'Y': 34, 'a': 35, 'b': 36, 'c': 37, 'd': 38, 'e': 39, 'f': 40, 'g': 41, 'h': 42, 'i': 43, 'j': 44, 'k': 45, 'l': 46, 'm': 47, 'n': 48, 'o': 49, 'p': 50, 'q': 51, 'r': 52, 's': 53, 't': 54, 'u': 55, 'v': 56, 'w': 57, 'x': 58, 'y': 59, 'z': 60}\n",
      "[17, 52, 49, 47, 1, 40, 35, 43, 52, 39, 53, 54, 1, 37, 52, 39, 35, 54, 55, 52, 39, 53, 1, 57, 39, 1, 38, 39, 53, 43, 52, 39, 1, 43, 48, 37, 52, 39, 35, 53, 39]\n"
     ]
    }
   ],
   "source": [
    "#load data back\n",
    "in_f = 'dark_char.txt'\n",
    "raw = load_doc(in_f)\n",
    "lines = raw.split('\\n')\n",
    "print(lines[0])\n",
    "\n",
    "#encode sequence\n",
    "chars = sorted(list(set(raw)))\n",
    "print(chars)\n",
    "\n",
    "mapping = dict((c,i) for i, c in enumerate(chars))\n",
    "print(mapping)\n",
    "\n",
    "encoded_sequence = list()\n",
    "for line in lines:\n",
    "    encoded_seq = [mapping[char] for char in line]\n",
    "    encoded_sequence.append(encoded_seq)\n",
    "print(encoded_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size is : 61\n"
     ]
    }
   ],
   "source": [
    "#vocab size\n",
    "vocab_size = len(mapping)\n",
    "print('vocab size is : {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93634, 40, 61)\n"
     ]
    }
   ],
   "source": [
    "encoded_sequence = array(encoded_sequence)\n",
    "X, y = encoded_sequence[:,:-1], encoded_sequence[:,-1]\n",
    "\n",
    "#dont understand here....looks like made it into tensor\n",
    "encoded_sequence = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = array(encoded_sequence)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "#removing those fucking annoying deprecated warning messages from tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def make_model(X, temperature=1):\n",
    "    model = Sequential()\n",
    "    #layer of 100-200 LSTM suggested by spec\n",
    "    model.add(LSTM(100, input_shape=(X.shape[1],X.shape[2])))\n",
    "    model.add(Lambda(lambda x: x * temperature)) #temperature layer as suggested in spec\n",
    "    #model.add(Dense(64, activation='relu')) #can add this layer for additional work if have time\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    #plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def gen_poem(model, mapping, seq_length, start_text, n_chars):\n",
    "    in_text = start_text\n",
    "    #modifying some shit since we want to print exactly 14 lines\n",
    "    for _ in range(n_chars): \n",
    "        #dont want to do while loop, if we get super long sentence, we are basically fucked\n",
    "        encoded = [mapping[char] for char in in_text]\n",
    "        \n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        \n",
    "        encoded = to_categorical(encoded, num_classes=len(mapping))\n",
    "        \n",
    "        #predict the next char\n",
    "        y_pred = model.predict_classes(encoded)\n",
    "        \n",
    "        #get the char for y_pred\n",
    "        char_pred = ''\n",
    "        for char, index in mapping.items():\n",
    "            if index == y_pred:\n",
    "                char_pred = char\n",
    "                break\n",
    "        \n",
    "        #append to our in_text\n",
    "        in_text += char_pred\n",
    "        \n",
    "        #do a '\\n' check\n",
    "        count = len(re.findall(\"\\n\", in_text))\n",
    "        if count == 14:\n",
    "            return in_text\n",
    "    print('no 14 lines...failed')\n",
    "    return in_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 100)               64800     \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 61)                6161      \n",
      "=================================================================\n",
      "Total params: 70,961\n",
      "Trainable params: 70,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "93634/93634 [==============================] - 42s 453us/step - loss: 2.8186 - acc: 0.2435\n",
      "Epoch 2/10\n",
      "93634/93634 [==============================] - 36s 383us/step - loss: 2.2773 - acc: 0.3504\n",
      "Epoch 3/10\n",
      "93634/93634 [==============================] - 39s 414us/step - loss: 2.1427 - acc: 0.3831\n",
      "Epoch 4/10\n",
      "93634/93634 [==============================] - 33s 347us/step - loss: 2.0625 - acc: 0.4018\n",
      "Epoch 5/10\n",
      "93634/93634 [==============================] - 33s 352us/step - loss: 1.9987 - acc: 0.4162\n",
      "Epoch 6/10\n",
      "93634/93634 [==============================] - 35s 374us/step - loss: 1.9416 - acc: 0.4272\n",
      "Epoch 7/10\n",
      "93634/93634 [==============================] - 35s 377us/step - loss: 1.8941 - acc: 0.4393\n",
      "Epoch 8/10\n",
      "93634/93634 [==============================] - 42s 444us/step - loss: 1.8521 - acc: 0.4509\n",
      "Epoch 9/10\n",
      "93634/93634 [==============================] - 41s 435us/step - loss: 1.8166 - acc: 0.4601\n",
      "Epoch 10/10\n",
      "93634/93634 [==============================] - 49s 527us/step - loss: 1.7866 - acc: 0.4677\n"
     ]
    }
   ],
   "source": [
    "###########temprature = 1.5\n",
    "rnn = make_model(X, temperature=1.5)\n",
    "#keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "rnn.fit(X, y, epochs=10, batch_size=256, callbacks=[EarlyStopping(monitor='acc', patience=2, verbose=0, mode='auto')])\n",
    "rnn.save('rnn.h5')\n",
    "dump(mapping, open('mapping.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no 14 lines...failed\n",
      "shall i compare thee to a summer's day?\n",
      "The so the self the with the self the will deart, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self the with thee, And the self the with the self\n"
     ]
    }
   ],
   "source": [
    "rnn150 = load_model('rnn.h5')\n",
    "mapping = load(open('mapping.pkl', 'rb'))\n",
    "fugma = \"shall i compare thee to a summer's day?\\n\"\n",
    "print(gen_poem(rnn150, mapping, 40, fugma, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100)               64800     \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 61)                6161      \n",
      "=================================================================\n",
      "Total params: 70,961\n",
      "Trainable params: 70,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "93634/93634 [==============================] - 98s 1ms/step - loss: 2.9952 - acc: 0.1917\n",
      "Epoch 2/20\n",
      "93634/93634 [==============================] - 35s 369us/step - loss: 2.6317 - acc: 0.2971\n",
      "Epoch 3/20\n",
      "93634/93634 [==============================] - 37s 398us/step - loss: 2.3890 - acc: 0.33130s - loss: 2.3893 - acc: 0.331\n",
      "Epoch 4/20\n",
      "93634/93634 [==============================] - 34s 363us/step - loss: 2.2806 - acc: 0.3491\n",
      "Epoch 5/20\n",
      "93634/93634 [==============================] - 39s 416us/step - loss: 2.2139 - acc: 0.3648\n",
      "Epoch 6/20\n",
      "93634/93634 [==============================] - 34s 360us/step - loss: 2.1677 - acc: 0.3730\n",
      "Epoch 7/20\n",
      "93634/93634 [==============================] - 33s 352us/step - loss: 2.1317 - acc: 0.3816\n",
      "Epoch 8/20\n",
      "93634/93634 [==============================] - 36s 381us/step - loss: 2.1023 - acc: 0.3900\n",
      "Epoch 9/20\n",
      "93634/93634 [==============================] - 39s 411us/step - loss: 2.0771 - acc: 0.3962\n",
      "Epoch 10/20\n",
      "93634/93634 [==============================] - 35s 379us/step - loss: 2.0543 - acc: 0.4016\n",
      "Epoch 11/20\n",
      "93634/93634 [==============================] - 41s 437us/step - loss: 2.0343 - acc: 0.4058\n",
      "Epoch 12/20\n",
      "93634/93634 [==============================] - 31s 328us/step - loss: 2.0160 - acc: 0.4109\n",
      "Epoch 13/20\n",
      "93634/93634 [==============================] - 29s 312us/step - loss: 1.9984 - acc: 0.4139\n",
      "Epoch 14/20\n",
      "93634/93634 [==============================] - 30s 318us/step - loss: 1.9816 - acc: 0.4171\n",
      "Epoch 15/20\n",
      "93634/93634 [==============================] - 30s 325us/step - loss: 1.9653 - acc: 0.4204\n",
      "Epoch 16/20\n",
      "93634/93634 [==============================] - 32s 343us/step - loss: 1.9504 - acc: 0.4239\n",
      "Epoch 17/20\n",
      "93634/93634 [==============================] - 35s 378us/step - loss: 1.9341 - acc: 0.4280\n",
      "Epoch 18/20\n",
      "93634/93634 [==============================] - 35s 379us/step - loss: 1.9211 - acc: 0.4322\n",
      "Epoch 19/20\n",
      "93634/93634 [==============================] - 50s 532us/step - loss: 1.9069 - acc: 0.4350\n",
      "Epoch 20/20\n",
      "93634/93634 [==============================] - 39s 417us/step - loss: 1.8952 - acc: 0.4392\n"
     ]
    }
   ],
   "source": [
    "###########temprature = 0.75\n",
    "rnn_075 = make_model(X, temperature=0.75)\n",
    "#keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "rnn_075.fit(X, y, epochs=20, batch_size=256, callbacks=[EarlyStopping(monitor='acc', patience=2, verbose=0, mode='auto')])\n",
    "rnn_075.save('rnn_075.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no 14 lines...failed\n",
      "shall i compare thee to a summer's day?\n",
      " the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store the store\n"
     ]
    }
   ],
   "source": [
    "rnn_075 = load_model('rnn_075.h5')\n",
    "mapping = load(open('mapping.pkl', 'rb'))\n",
    "fugma = \"shall i compare thee to a summer's day?\\n\"\n",
    "print(gen_poem(rnn_075, mapping, 40, fugma, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 100)               64800     \n",
      "_________________________________________________________________\n",
      "lambda_8 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 61)                6161      \n",
      "=================================================================\n",
      "Total params: 70,961\n",
      "Trainable params: 70,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "93634/93634 [==============================] - 86s 917us/step - loss: 3.0697 - acc: 0.1869\n",
      "Epoch 2/20\n",
      "93634/93634 [==============================] - 79s 849us/step - loss: 3.0139 - acc: 0.1877\n",
      "Epoch 3/20\n",
      "93634/93634 [==============================] - 82s 877us/step - loss: 2.9673 - acc: 0.1877\n",
      "Epoch 4/20\n",
      "93634/93634 [==============================] - 89s 953us/step - loss: 2.9022 - acc: 0.1989\n",
      "Epoch 5/20\n",
      "93634/93634 [==============================] - 115s 1ms/step - loss: 2.8469 - acc: 0.2327\n",
      "Epoch 6/20\n",
      "93634/93634 [==============================] - 115s 1ms/step - loss: 2.7987 - acc: 0.2494 5s - loss: 2.8002 - acc:  - ETA\n",
      "Epoch 7/20\n",
      "93634/93634 [==============================] - 119s 1ms/step - loss: 2.7553 - acc: 0.2639\n",
      "Epoch 8/20\n",
      "93634/93634 [==============================] - 123s 1ms/step - loss: 2.7171 - acc: 0.2852\n",
      "Epoch 9/20\n",
      "93634/93634 [==============================] - 123s 1ms/step - loss: 2.6829 - acc: 0.2925\n",
      "Epoch 10/20\n",
      "93634/93634 [==============================] - 133s 1ms/step - loss: 2.6524 - acc: 0.2980\n",
      "Epoch 11/20\n",
      "93634/93634 [==============================] - 130s 1ms/step - loss: 2.6257 - acc: 0.3012\n",
      "Epoch 12/20\n",
      "93634/93634 [==============================] - 140s 1ms/step - loss: 2.6033 - acc: 0.3042\n",
      "Epoch 13/20\n",
      "93634/93634 [==============================] - 149s 2ms/step - loss: 2.5839 - acc: 0.3063\n",
      "Epoch 14/20\n",
      "93634/93634 [==============================] - 153s 2ms/step - loss: 2.5659 - acc: 0.3086\n",
      "Epoch 15/20\n",
      "93634/93634 [==============================] - 157s 2ms/step - loss: 2.5507 - acc: 0.3080\n",
      "Epoch 16/20\n",
      "93634/93634 [==============================] - 156s 2ms/step - loss: 2.5375 - acc: 0.3098 2s - loss: 2.5370 -\n",
      "Epoch 17/20\n",
      "93634/93634 [==============================] - 136s 1ms/step - loss: 2.5251 - acc: 0.3101\n",
      "Epoch 18/20\n",
      "93634/93634 [==============================] - 138s 1ms/step - loss: 2.5147 - acc: 0.3112\n",
      "Epoch 19/20\n",
      "93634/93634 [==============================] - 150s 2ms/step - loss: 2.5062 - acc: 0.3104\n",
      "Epoch 20/20\n",
      "93634/93634 [==============================] - 161s 2ms/step - loss: 2.4982 - acc: 0.3120\n"
     ]
    }
   ],
   "source": [
    "###########temprature = 0.25\n",
    "rnn_025 = make_model(X, temperature=0.25)\n",
    "#keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "rnn_025.fit(X, y, epochs=20, batch_size=128, callbacks=[EarlyStopping(monitor='acc', patience=2, verbose=0, mode='auto')])\n",
    "rnn_025.save('rnn_025.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no 14 lines...failed\n",
      "shall i compare thee to a summer's day?\n",
      " the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "rnn_025 = load_model('rnn_025.h5')\n",
    "mapping = load(open('mapping.pkl', 'rb'))\n",
    "fugma = \"shall i compare thee to a summer's day?\\n\"\n",
    "print(gen_poem(rnn_025, mapping, 40, fugma, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
