{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "from functools import partial\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of poems: 154\n"
     ]
    }
   ],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read().lower().split('\\n')\n",
    "poem_list = []\n",
    "raw_text = ''\n",
    "for j in range(len(text) + 1):\n",
    "    if j == len(text):\n",
    "        poem_list.append(raw_text)\n",
    "    elif text[j] == '':\n",
    "        if raw_text != '':\n",
    "            poem_list.append(raw_text)\n",
    "        raw_text = ''\n",
    "        continue\n",
    "    elif text[j][-1].isdigit():\n",
    "        continue\n",
    "    else:\n",
    "        subsentence = text[j] + '\\n'\n",
    "        raw_text += subsentence  \n",
    "print('Number of poems:', len(poem_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize into sequences of characters\n",
    "def create_sequence(raw_text, length, step):\n",
    "    sequences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(raw_text) - length, step):\n",
    "        # select sequence of tokens\n",
    "        seq = raw_text[i:i + length]\n",
    "        # store\n",
    "        sequences.append(seq)\n",
    "        next_chars.append(raw_text[i + length])\n",
    "    return sequences, next_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 88130\n"
     ]
    }
   ],
   "source": [
    "length = 40\n",
    "step = 1\n",
    "sequences = []\n",
    "next_chars = []\n",
    "for poem in poem_list:\n",
    "    sub_sequences, sub_next_chars = create_sequence(poem, length, step)\n",
    "    sequences += sub_sequences\n",
    "    next_chars += sub_next_chars\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Mappings and Inverse Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 38\n"
     ]
    }
   ],
   "source": [
    "poem_string = \"\".join(poem_list)\n",
    "chars = sorted(list(set(poem_string)))\n",
    "char_index_map = dict((c, i) for i, c in enumerate(chars))\n",
    "index_char_map = dict((i, c) for i, c in enumerate(chars))\n",
    "vocab_size = len(char_index_map)\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sequences), length, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sequences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_index_map[char]] = 1\n",
    "    y[i, char_index_map[next_chars[i]]] = 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the RNN Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               85504     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 38)                4902      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 38)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 38)                0         \n",
      "=================================================================\n",
      "Total params: 90,406\n",
      "Trainable params: 90,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(length, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Dropout(0.111))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()   \n",
    "\n",
    "optimizer = RMSprop(lr=0.006738)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling function (combining softmax with temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model with outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Steve\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "88130/88130 [==============================] - 92s 1ms/step - loss: 2.3135 - acc: 0.3444\n",
      "Epoch 2/10\n",
      "88130/88130 [==============================] - 94s 1ms/step - loss: 1.9405 - acc: 0.4373\n",
      "Epoch 3/10\n",
      "88130/88130 [==============================] - 97s 1ms/step - loss: 1.8227 - acc: 0.4665\n",
      "Epoch 4/10\n",
      "88130/88130 [==============================] - 104s 1ms/step - loss: 1.7512 - acc: 0.4846\n",
      "Epoch 5/10\n",
      "88130/88130 [==============================] - 115s 1ms/step - loss: 1.6946 - acc: 0.4991\n",
      "Epoch 6/10\n",
      "88130/88130 [==============================] - 122s 1ms/step - loss: 1.6520 - acc: 0.5116 9s - loss: 1. - E\n",
      "Epoch 7/10\n",
      "88130/88130 [==============================] - 131s 1ms/step - loss: 1.6117 - acc: 0.5241 5s - loss: 1.6115 -  - ETA: 2s - loss: 1.61\n",
      "Epoch 8/10\n",
      "45184/88130 [==============>...............] - ETA: 1:12 - loss: 1.5643 - acc: 0.5351"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for iteration in range(10):\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=10)\n",
    "\n",
    "    for temperature in [1.5, 0.75, 0.25]:\n",
    "        print()\n",
    "        print('----- temperature parameter:', temperature)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = \"shall i compare thee to a summer's day?\\n\"\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        line_count = 0\n",
    "        while (line_count <= 12):\n",
    "            x = np.zeros((1, length, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_index_map[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = index_char_map[next_index]\n",
    "            \n",
    "            if next_char == '\\n':\n",
    "                line_count += 1\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
